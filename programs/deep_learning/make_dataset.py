# dataset_rppg.py
from pathlib import Path
from typing import Optional, List, Tuple, Dict, Iterable
import json, re, datetime
import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset
from scipy.signal import resample_poly
import tkinter as tk
from tkinter import messagebox

# ä¾å­˜: æ—¢å­˜ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
from myutils.select_folder import select_folder, select_file
from myutils.load_and_save_folder import load_ppg_pulse
from pulsewave.processing_pulsewave import detrend_pulse, bandpass_filter_pulse

# ===== IDæŠ½å‡º: 3æ¡å„ªå…ˆâ†’ç„¡ã‘ã‚Œã°æœ€åˆã®æ•°å­—åˆ— =====
_ID3_RE = re.compile(r"(?<!\d)(\d{3})(?!\d)")
_NUM_RE = re.compile(r"(\d+)")
def _extract_sid(stem: str) -> Optional[int]:
    m3 = _ID3_RE.search(stem)
    if m3: return int(m3.group(1))
    m = _NUM_RE.search(stem)
    return int(m.group(1)) if m else None

# last_folders.json ã¯ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®éš£ã«å›ºå®šï¼ˆcwdã«ä¾å­˜ã—ãªã„ï¼‰
HERE = Path(__file__).resolve().parent
CONFIG_PATH = HERE / "last_folders.json"

def ask_yes_no(msg: str) -> bool:
    root = tk.Tk(); root.withdraw()
    return messagebox.askyesno("ç¢ºèª", msg)

def _pick_or_load_folders() -> Dict[str, Path]:
    labels = ["ICA", "POS", "CHROM", "LGI", "OMIT", "PPGï¼ˆROIãªã—/phaseå›ºå®šï¼‰"]
    if CONFIG_PATH.exists() and ask_yes_no("å‰å›ã¨åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½¿ç”¨ã—ã¾ã™ã‹ï¼Ÿ"):
        try:
            with open(CONFIG_PATH, "r", encoding="utf-8") as f:
                saved = json.load(f)
            return {label: Path(saved[label]) for label in labels}
        except Exception:
            pass  # ç ´æã—ã¦ãŸã‚‰é¸ã³ç›´ã—ã¸
    folders = {}
    for label in labels:
        p = select_folder(message=f"{label} ãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠã—ã¦ãã ã•ã„")
        if not p:
            raise RuntimeError(f"{label} ã®ãƒ•ã‚©ãƒ«ãƒ€é¸æŠãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚")
        folders[label] = Path(p)
    with open(CONFIG_PATH, "w", encoding="utf-8") as f:
        json.dump({k: str(v) for k, v in folders.items()}, f, ensure_ascii=False, indent=2)
    return folders

def _build_index(folder: Path, suffixes: Iterable[str]=(".csv", ".CSV", ".txt", ".TXT")) -> Dict[int, Path]:
    """ãƒ•ã‚©ãƒ«ãƒ€é…ä¸‹ã‚’å†å¸°æ¢ç´¢ã—ã¦ {sid: Path} ã‚’ä½œã‚‹"""
    idx: Dict[int, Path] = {}
    for suf in suffixes:
        for p in folder.rglob(f"*{suf}"):
            sid = _extract_sid(p.stem)
            if sid is None: 
                continue
            idx[sid] = p
    return idx

def load_pulse(filepath: Path):
    try:
        df = pd.read_csv(filepath, sep=None, engine="python")
        cols_lower = {c.lower(): c for c in df.columns}
        df["time_sec"] = pd.to_numeric(df[cols_lower["time_sec"]], errors="raise")
        df["value"]    = pd.to_numeric(df[cols_lower["value"]],    errors="raise")
        return df
    except Exception as e:
        print(f"[load_pulse] èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {filepath} / {e}")
        return None

def preprocess_ppg_signal(ppg_signal: np.ndarray, fs_ppg: int = 100, fs_target: int = 30) -> np.ndarray:
    ppg_ds = resample_poly(ppg_signal, up=3, down=10, window=('kaiser', 5.0))
    try:
        ppg_dt = detrend_pulse(ppg_ds, sample_rate=fs_target)
    except Exception:
        from scipy.signal import detrend
        ppg_dt = detrend(ppg_ds)
    ppg_bp = bandpass_filter_pulse(ppg_dt, band_width=[0.1, 10.0], sample_rate=fs_target)
    ppg_bp = -ppg_bp
    return ppg_bp.astype(np.float32)

def windowize(X: np.ndarray, y: np.ndarray, fs: int, win_sec: int, hop_sec: int):
    win, hop, T = win_sec * fs, hop_sec * fs, len(y)
    out = []
    for s in range(0, T - win + 1, hop):
        xs = X[s:s+win, :].astype(np.float32)
        ys = y[s:s+win].astype(np.float32)
        xs = (xs - xs.mean(axis=0)) / (xs.std(axis=0) + 1e-8)
        ys = (ys - ys.mean()) / (ys.std() + 1e-8)
        out.append((xs, ys[:, None]))
    return out

class RppgPpgDataset(Dataset):
    """
    èµ·å‹•æ™‚ã«:
      1) æ—¢å­˜ã‚­ãƒ£ãƒƒã‚·ãƒ¥(.pt)ã‹ã‚‰èª­ã¿è¾¼ã‚€ã‹ç¢ºèª â†’ ã¯ã„â†’ select_file ã§é¸æŠâ†’ å³ãƒ­ãƒ¼ãƒ‰
      2) ã„ã„ãˆâ†’ 6ãƒ•ã‚©ãƒ«ãƒ€ã‚’ select_folder â†’ å‰å‡¦ç†â†’ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åŒ–â†’ ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ã‚’ select_folder â†’ .pt ä¿å­˜
    """
    def __init__(self, *, fs:int, win_sec:int, hop_sec:int,
                 subj_start:Optional[int]=None, subj_end:Optional[int]=None,
                 omit_ids:Optional[List[int]]=None, allow_txt:bool=False, fs_ppg_src:int=100):
        self.fs = fs; self.win_sec = win_sec; self.hop_sec = hop_sec
        self.fs_ppg_src = fs_ppg_src
        self.X = None; self.y = None

        # 1) æ—¢å­˜ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã‚€ï¼Ÿ
        if ask_yes_no("æ—¢å­˜ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆ.ptï¼‰ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã™ã‹ï¼Ÿ"):
            p = select_file(message="ã‚­ãƒ£ãƒƒã‚·ãƒ¥(.pt)ã‚’é¸æŠã—ã¦ãã ã•ã„")
            if not p:
                raise RuntimeError("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®é¸æŠãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚")
            cache_path = Path(p)
            if cache_path.suffix.lower() != ".pt":
                raise RuntimeError("é¸æŠã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒ .pt ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            if not cache_path.exists():
                raise RuntimeError(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {cache_path}")
            pack = torch.load(cache_path, map_location="cpu")
            self.X, self.y, self.meta = pack["X"], pack["y"], pack["meta"]
            print(f"âš¡ Loaded cache: {cache_path}  X={self.X.shape}, y={self.y.shape}")
            return

        # 2) ãƒ•ã‚©ãƒ«ãƒ€é¸æŠ â†’ ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        folders = _pick_or_load_folders()
        suff = (".csv", ".CSV", ".txt", ".TXT") if allow_txt else (".csv", ".CSV")
        idx_ica   = _build_index(folders["ICA"],   suff)
        idx_pos   = _build_index(folders["POS"],   suff)
        idx_chrom = _build_index(folders["CHROM"], suff)
        idx_lgi   = _build_index(folders["LGI"],   suff)
        idx_omit  = _build_index(folders["OMIT"],  suff)
        idx_ppg   = _build_index(folders["PPGï¼ˆROIãªã—/phaseå›ºå®šï¼‰"], suff)

        # ãƒ‡ãƒãƒƒã‚°: åé›†çŠ¶æ³
        inter = set(idx_ica) & set(idx_pos) & set(idx_chrom) & set(idx_lgi) & set(idx_omit) & set(idx_ppg)
        print("IDs åé›†ä»¶æ•°:",
              "ICA", len(idx_ica), "POS", len(idx_pos), "CHROM", len(idx_chrom),
              "LGI", len(idx_lgi), "OMIT", len(idx_omit), "PPG", len(idx_ppg))
        print("äº¤å·®ï¼ˆç¯„å›²ãƒ•ã‚£ãƒ«ã‚¿å‰ï¼‰:", len(inter))

        ids = inter
        if (subj_start is not None) and (subj_end is not None):
            ids &= set(range(subj_start, subj_end+1))
        if omit_ids:
            ids -= set(omit_ids)

        if not ids:
            raise RuntimeError("å…±é€šã®è¢«é¨“è€…ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚©ãƒ«ãƒ€é¸æŠãƒ»æ‹¡å¼µå­ãƒ»IDæŠ½å‡ºè¦å‰‡ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        windows_X, windows_y = [], []
        for sid in sorted(ids):
            dfs = [load_pulse(idx) for idx in (idx_lgi[sid], idx_pos[sid], idx_chrom[sid], idx_ica[sid], idx_omit[sid])]
            if any(d is None for d in dfs):
                print(f"âš ï¸ skip {sid:03d} - èª­ã¿è¾¼ã¿å¤±æ•—")
                continue
            df_ppg = load_ppg_pulse(idx_ppg[sid])
            if df_ppg is None:
                print(f"âš ï¸ skip {sid:03d} - PPG èª­ã¿è¾¼ã¿å¤±æ•—")
                continue

            try:
                s_lgi, s_pos, s_chrom, s_ica, s_omit = [d["value"].to_numpy(dtype=float) for d in dfs]
                s_ppg = df_ppg["value"].to_numpy(dtype=float)
            except KeyError:
                print(f"âš ï¸ skip {sid:03d} - 'value' åˆ—ãŒä¸è¶³")
                continue

            s_ppg = preprocess_ppg_signal(s_ppg, fs_ppg=fs_ppg_src, fs_target=self.fs)
            T = min(map(len, [s_lgi, s_pos, s_chrom, s_ica, s_omit, s_ppg]))
            X = np.stack([s_lgi[:T], s_pos[:T], s_chrom[:T], s_ica[:T], s_omit[:T]], axis=1)
            y = s_ppg[:T]

            for xs, ys in windowize(X, y, self.fs, self.win_sec, self.hop_sec):
                windows_X.append(xs); windows_y.append(ys)

        if not windows_X:
            raise RuntimeError("ã‚µãƒ³ãƒ—ãƒ«0ä»¶ã€‚çª“è¨­å®šã‚„ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        self.X = torch.from_numpy(np.stack(windows_X)).contiguous().float()
        self.y = torch.from_numpy(np.stack(windows_y)).contiguous().float()
        self.meta = {
            "fs": fs, "win_sec": win_sec, "hop_sec": hop_sec,
            "fs_ppg_src": fs_ppg_src, "N_windows": int(self.X.shape[0]),
            "timestamp": datetime.datetime.now().isoformat(timespec="seconds")
        }

        # 3) ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ã‚’ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã§é¸ã¶
        save_dir = select_folder(message="ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠã—ã¦ãã ã•ã„")
        if not save_dir:
            raise RuntimeError("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ãƒ•ã‚©ãƒ«ãƒ€ã®é¸æŠãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚")
        save_dir = Path(save_dir)
        fname = f"rppg_win{win_sec}_hop{hop_sec}_fs{fs}.pt"
        cache_path = save_dir / fname
        torch.save({"X": self.X, "y": self.y, "meta": self.meta}, cache_path)
        print(f"ğŸ’¾ Saved cache: {cache_path}  X={self.X.shape}, y={self.y.shape}")

    def __len__(self): 
        return self.X.shape[0]
    def __getitem__(self, idx): 
        return self.X[idx], self.y[idx]



class SingleSubjectDataset(Dataset):
    """
    èµ·å‹•æ™‚:
      1) æ—¢å­˜JSONã‚’ä½¿ã†ã‹GUIã§ç¢ºèªã€‚
         â†’ ã¯ã„: select_file() ã§ JSON é¸æŠ â†’ å„CSVã‚’èª­ã¿è¾¼ã¿ã€‚
         â†’ ã„ã„ãˆ: å„CSVã‚’æ‰‹å‹•ã§é¸æŠ â†’ JSONã‚’è‡ªå‹•ç”Ÿæˆã—ã¦ä¿å­˜ã€‚
      2) å…¨ãƒãƒ£ãƒãƒ«ã‚’èª­ã¿è¾¼ã¿ãƒ»æ•´åˆ—ã—ã€X:(T,5), y:(T,) ã¨ã—ã¦ä¿æŒã€‚
      3) ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åˆ†å‰²ã¯è¡Œã‚ãªã„ã€‚
    """

    def __init__(self, fs_rppg: int = 30, fs_ppg_src: int = 100,
                 bp_low: float = 0.7, bp_high: float = 3.0, detrend: bool = True):
        self.fs_rppg = fs_rppg
        self.fs_ppg_src = fs_ppg_src
        self.bp_low = bp_low
        self.bp_high = bp_high
        self.detrend = detrend

        self.X: torch.Tensor
        self.y: torch.Tensor
        self.meta = {}
        self.paths = {}

        # === ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆJSONï¼‰èª­ã¿è¾¼ã¿ã‹æ–°è¦ç”Ÿæˆã‹ ===
        if ask_yes_no("æ—¢å­˜ã®è¢«é¨“è€…JSONï¼ˆä¾‹: subject_1020.jsonï¼‰ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã‹ï¼Ÿ"):
            json_path = Path(select_file(message="è¢«é¨“è€…JSONã‚’é¸æŠã—ã¦ãã ã•ã„"))
            if not json_path.exists():
                raise RuntimeError("JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            with open(json_path, "r", encoding="utf-8") as f:
                info = json.load(f)

            self.paths = info["paths"]
            self.meta = info.get("meta", {})
            self.subject_id = info.get("subject_id", "unknown")
            print(f"âœ… Loaded JSON: {json_path}")
        else:
            # --- æ–°è¦ä½œæˆ ---
            print("ğŸ“„ LGI CSV ã‚’é¸æŠã—ã¦ãã ã•ã„");   f_lgi = Path(select_file())
            print("ğŸ“„ POS CSV ã‚’é¸æŠã—ã¦ãã ã•ã„");   f_pos = Path(select_file())
            print("ğŸ“„ CHROM CSV ã‚’é¸æŠã—ã¦ãã ã•ã„"); f_chrom = Path(select_file())
            print("ğŸ“„ ICA CSV ã‚’é¸æŠã—ã¦ãã ã•ã„");   f_ica = Path(select_file())
            print("ğŸ“„ OMIT CSV ã‚’é¸æŠã—ã¦ãã ã•ã„");  f_omit = Path(select_file())
            print("ğŸ“„ PPG CSV ã‚’é¸æŠã—ã¦ãã ã•ã„");    f_ppg = Path(select_file())

            self.paths = {
                "lgi": str(f_lgi),
                "pos": str(f_pos),
                "chrom": str(f_chrom),
                "ica": str(f_ica),
                "omit": str(f_omit),
                "ppg": str(f_ppg),
            }

            # è¢«é¨“è€…IDã‚’ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ¨å®š
            try:
                import re
                m = re.search(r"(\d{3,4})", f_lgi.stem)
                self.subject_id = int(m.group(1)) if m else "unknown"
            except Exception:
                self.subject_id = "unknown"

            self.meta = {
                "fs_rppg": fs_rppg,
                "fs_ppg_src": fs_ppg_src,
                "bp": [bp_low, bp_high],
                "detrend": detrend,
            }

            # JSONä¿å­˜
            out_json = Path(f"./subject_{self.subject_id}.json")
            with open(out_json, "w", encoding="utf-8") as f:
                json.dump(
                    {"subject_id": self.subject_id, "paths": self.paths, "meta": self.meta},
                    f, ensure_ascii=False, indent=2
                )
            print(f"ğŸ’¾ Saved JSON: {out_json}")

        # === CSVãƒ­ãƒ¼ãƒ‰ ===
        print("ğŸ“¥ Loading signals...")
        df_lgi   = load_pulse(Path(self.paths["lgi"]))
        df_pos   = load_pulse(Path(self.paths["pos"]))
        df_chrom = load_pulse(Path(self.paths["chrom"]))
        df_ica   = load_pulse(Path(self.paths["ica"]))
        df_omit  = load_pulse(Path(self.paths["omit"]))
        df_ppg   = load_ppg_pulse(Path(self.paths["ppg"]))

        # PPGã®ã¿å‰å‡¦ç†
        s_lgi =df_lgi["value"].to_numpy(dtype=float)
        s_pos =df_pos["value"].to_numpy(dtype=float)
        s_ica =df_ica["value"].to_numpy(dtype=float)
        s_chrom =df_chrom["value"].to_numpy(dtype=float)
        s_omit =df_omit["value"].to_numpy(dtype=float)
        
        s_ppg = df_ppg["value"].to_numpy(dtype=float)
        s_ppg = preprocess_ppg_signal(
            s_ppg, fs_ppg=100, fs_target=30)

        # é•·ã•åˆã‚ã›
        T = min(map(len, [s_lgi, s_pos, s_chrom, s_ica, s_omit, s_ppg]))
        X = np.stack([s_lgi[:T], s_pos[:T], s_chrom[:T], s_ica[:T], s_omit[:T]], axis=1)
        y = s_ppg[:T]

        # torchåŒ–
        self.X = torch.from_numpy(X).float()
        self.y = torch.from_numpy(y).float()

        print(f"âœ… Data ready: X={self.X.shape}, y={self.y.shape}, subject={self.subject_id}")

    def __len__(self):
        return self.X.shape[0]

    def __getitem__(self, idx):
        # å„ã‚µãƒ³ãƒ—ãƒ«ã¯ (1æ™‚åˆ», å…¨5ch) ã¨ãã® yå€¤ã‚’è¿”ã™
        return self.X[idx], self.y[idx]