# infer_folder_jsonpaths_kfold.py
import os, json, traceback, glob
from pathlib import Path
import numpy as np
import pandas as pd
import torch
import tkinter as tk
from tkinter import messagebox

from myutils.select_folder import select_folder, select_file
from deep_learning.lstm import ReconstractedPPG_Net,ReconstractPPG_withAttention
from deep_learning.make_dataset import batchSubjectDataset

os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"


def ask_yes_no(msg: str) -> bool:
    root = tk.Tk(); root.withdraw()
    ans = messagebox.askyesno("ç¢ºèª", msg)
    root.destroy()
    return ans


def load_fold_models(model_dir: Path,
                     input_size=5,
                     lstm_dims=(90,60,30),
                     drop=0.2,
                     device="cpu"):
    """
    model_dir é…ä¸‹ã® fold_* ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ .pth ã‚’å…¨æ¢ç´¢ã—ã€foldã”ã¨ã«æœ€æ–°or1å€‹ã‚’ãƒ­ãƒ¼ãƒ‰ã€‚
    è¿”ã‚Šå€¤: [model0, model1, ...], [ckpt_path0, ckpt_path1, ...]
    """
    fold_ckpts = []
    for fold_path in sorted(model_dir.glob("fold_*")):
        # foldãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªé…ä¸‹ã® .pth ã‚’æ‹¾ã†ï¼ˆ1ã¤æƒ³å®šã€è¤‡æ•°ã‚ã‚‹ãªã‚‰ä¸€ç•ªæ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        pths = sorted(fold_path.glob("*.pth"), key=lambda p: p.stat().st_mtime)
        if len(pths) == 0:
            continue
        fold_ckpts.append(pths[-1])  # æœ€ã‚‚æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«

    if len(fold_ckpts) == 0:
        raise FileNotFoundError(f"'{model_dir}' é…ä¸‹ã« fold_*/ *.pth ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    models, used_paths = [], []
    for ckpt in fold_ckpts:
        model = ReconstractPPG_withAttention(
            input_size=input_size,
            lstm_dims=lstm_dims,
            drop=drop
        ).to(device)
        state = torch.load(ckpt, map_location=device)
        model.load_state_dict(state)
        model.eval()
        models.append(model)
        used_paths.append(ckpt)

    print("âœ… èª­ã¿è¾¼ã‚“ã foldãƒ¢ãƒ‡ãƒ«:")
    for i, p in enumerate(used_paths, 1):
        print(f"  F{i}: {p}")
    return models, used_paths


@torch.no_grad()
def predict_ensemble(models, X_np: np.ndarray, device="cpu"):
    """
    X_np: (T, 5) 60ç§’ãªã©ãƒ•ãƒ«é•·
    å„foldãƒ¢ãƒ‡ãƒ«ã§æ¨è«– â†’ å¹³å‡ã€‚å€‹åˆ¥å‡ºåŠ›ã‚‚è¿”ã™ã€‚
    æˆ»ã‚Š:
      y_mean      : (T,)
      y_by_fold   : list of (T,)
    """
    x_t = torch.from_numpy(X_np).float().unsqueeze(0).to(device)  # (1, T, 5)

    y_list = []
    for m in models:
        y_hat= m(x_t)          # (1, T, 1), (1, T, 1)
        y = y_hat.squeeze(0).detach().cpu().numpy()[:, 0]   # (T,)
        y_list.append(y)
        

    y_stack = np.stack(y_list, axis=0)  # (F, T)
    y_mean = np.mean(y_stack, axis=0)   # (T,)
    return y_mean,y_list


def main():
    # ==== æ¨è«–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ====
    EXP_NAME   = "glallea_before_lstm5_attention_kfold_infer"
    LSTM_DIMS  = (120,90, 60)
    CNN_HIDDEN = 32
    DROPOUT    = 0.2
    FS         = 30   # rPPGã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆï¼ˆå­¦ç¿’æ™‚ã«åˆã‚ã›ã‚‹ï¼‰
    SAVE_INDIVIDUAL_FOLDS = True  # å„foldã®äºˆæ¸¬åˆ—ã‚‚CSVã«å‡ºã™

    device = "cuda" if torch.cuda.is_available() else "cpu"

    OUT_ROOT = Path("./result-trained-model") / EXP_NAME
    OUT_ROOT.mkdir(parents=True, exist_ok=True)

    # ==== ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ«ãƒ€é¸æŠï¼ˆfold_* ã‚’æŸã­ã¦ã„ã‚‹è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’é¸ã¶ï¼‰====
    print("k-foldã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒå…¥ã£ãŸè¦ªãƒ•ã‚©ãƒ«ãƒ€ï¼ˆfold_*/ ãŒä¸¦ã¶ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰ã‚’é¸æŠã—ã¦ãã ã•ã„")
    model_root = Path(select_folder())

    # ã™ã¹ã¦ã®foldãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
    models, used_ckpts = load_fold_models(
        model_dir=model_root,
        input_size=5,
        lstm_dims=LSTM_DIMS,
        drop=DROPOUT,
        device=device
    )

    # ==== JSONãƒ•ã‚©ãƒ«ãƒ€é¸æŠ ====
    print("JSONãŒè¤‡æ•°å…¥ã£ãŸãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠã—ã¦ãã ã•ã„")
    json_dir = Path(select_folder())
    json_files = sorted(p for p in json_dir.glob("*.json"))
    if not json_files:
        print("âš ï¸ *.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚çµ‚äº†ã—ã¾ã™ã€‚")
        return

    print(f"ğŸ” å¯¾è±¡JSON: {len(json_files)}ä»¶")

    # é€²æ—è¨˜éŒ²
    summary_rows = []

    for jpath in json_files:
        print(f"\n=== {jpath.name} ã‚’å‡¦ç†ä¸­ ===")
        try:
            # 60ç§’ãƒ•ãƒ«æ³¢å½¢ï¼ˆor JSONãŒæŒã¤å…¨é•·ï¼‰ã‚’ãã®ã¾ã¾èª­ã¿è¾¼ã‚€
            dataset = batchSubjectDataset(fs_rppg=FS, fs_ppg_src=100, json_path=jpath)
            X = dataset.X.numpy()       # (T,5)
            y_true = dataset.y.numpy()  # (T,)
            subj_id = getattr(dataset, "subject_id", "unknown")
            roi_name = getattr(dataset, "roi_name", "unknown")
            print(f"âœ… Dataset loaded: X={X.shape}, y={y_true.shape}, subject={subj_id}, roi={roi_name}")

            # k-foldã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ¨è«–ï¼ˆãƒ•ãƒ«é•·ï¼‰
            y_pred_mean, y_by_fold = predict_ensemble(models, X, device=device)

            # å‡ºåŠ›
            T = X.shape[0]
            t = np.arange(T) / FS
            out_dict = {
                "time_sec": t,
                "true_ppg": y_true,
                "pred_ppg_mean": y_pred_mean,
                "lgi": X[:, 0],
                "pos": X[:, 1],
                "chrom": X[:, 2],
                "ica": X[:, 3],
                "omit": X[:, 4],
            }
            if SAVE_INDIVIDUAL_FOLDS:
                for  i,y_f in enumerate (y_by_fold):
                    out_dict[f"pred_ppg_f{i}"] = y_f

            df_out = pd.DataFrame(out_dict)

            out_csv = OUT_ROOT / f"subject_{subj_id}_{roi_name}_pred_kfold.csv"
            df_out.to_csv(out_csv, index=False, encoding="utf-8-sig")
            print(f"âœ… å‡ºåŠ›å®Œäº†: {out_csv}")

            summary_rows.append({
                "json": jpath.name,
                "subject_id": subj_id,
                "roi_name": roi_name,
                "T": T,
                "n_folds": len(models),
                "out_csv": str(out_csv),
            })

        except Exception as e:
            print(f"âŒ å¤±æ•—: {jpath.name}")
            traceback.print_exc()
            summary_rows.append({
                "json": jpath.name,
                "subject_id": "unknown",
                "roi_name": "unknown",
                "T": 0,
                "n_folds": len(models),
                "out_csv": "",
                "error": str(e),
            })

    # ã‚µãƒãƒªCSV
    if summary_rows:
        df_sum = pd.DataFrame(summary_rows)
        df_sum.to_csv(OUT_ROOT / "summary.csv", index=False, encoding="utf-8-sig")
        print(f"\nğŸ“„ summary.csv ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {OUT_ROOT / 'summary.csv'}")


if __name__ == "__main__":
    main()
